{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "duration": "30 minutes"
   },
   "source": [
    "# Machine Learning with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning about Humans learning ML\n",
    "\n",
    "Let us load the massaged and moderately feature engineered data that we created in the previous lecture.  The `X` and `y` for this cleaned up dataset are saved in this repository as separate CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   \n",
    "\n",
    "# read in two csv files, which are already \"processed\"\n",
    "\n",
    "X = pd.read_csv('data/HumansLearning_X.csv', index_col=0)\n",
    "\n",
    "\n",
    "# single column, no header in the csv file\n",
    "y = pd.read_csv('data/HumansLearning_y.csv', squeeze=True, header=None) \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importances in decision tree\n",
    "\n",
    "To see what is the \"best possible\" decision tree for this dataset, let's deliberately \"overfit\" by including all the observations in the model.  This improves predictive power somewhat, as one would expect.\n",
    "\n",
    "The feature importances identified by this classifier **are not the same as—nor even necessarily particularly similar to**—those that would be produced by other classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=7, random_state=0)  # define maximum depth of DT\n",
    "tree.fit(X, y)\n",
    "tree.score(X, y)  # output average accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.Series(tree.feature_importances_, index=X.columns).plot.barh(figsize=(8,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut points in a Decision Tree\n",
    "\n",
    "Beside seeing what features are most important in this trained model, we can use a lovely utility method in `sklearn.tree` to display the entire tree and its decision cuts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out where graphviz executable lives\n",
    "dotpath = !which dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate cut point diagram\n",
    "from sklearn.tree import export_graphviz\n",
    "import sys, subprocess\n",
    "from IPython.display import Image\n",
    "\n",
    "export_graphviz(tree, feature_names=X.columns, class_names=['failure','success'],\n",
    "                out_file='ml-good.dot', impurity=False, filled=True)\n",
    "subprocess.check_call([dotpath[0],'-Tpng','ml-good.dot','-o','ml-good.png'])\n",
    "Image('ml-good.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the diagram, blue branches reflect those respondents who found the tutorial more successful, and orange branches those who found it less so. The saturation of the displayed boxes reflects the strength of that decision branch.\n",
    "\n",
    "As seems obvious in retrospect, the fans of *[And Now for Something Completely Different](https://en.wikipedia.org/wiki/And_Now_for_Something_Completely_Different)* really did not like the scikit-learn tutorial. Years of Python experience is a slightly more important feature, but it follows an oddly stratified pattern wherein several **different ranges of years** show positive or negative effects—it's not linear.\n",
    "\n",
    "And of course, *[Time Bandits](https://en.wikipedia.org/wiki/Time_Bandits)* was not a Monty Python film at all: it is a Terry Gilliam film that happened to cast a number of Monty Python cast members. What on earth were those respondents thinking?!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A common API\n",
    "\n",
    "As stated in the introduction to this course that one of the great virtues of scikit-learn is its use of a common API across many different model classes.  For practice, let us look at a typical pattern again for `DecisionTreeClassifier` followed by the same pattern for `DummyClassifier`.  This latter is a good sanity check of how well you might predict without really trying and/or without doing anything particularly meaningful to train against the data.\n",
    "\n",
    "There are several \"strategies\" that `DummyClassifier` might use:\n",
    "\n",
    "* `stratified`: generates predictions by respecting the training set’s class distribution.\n",
    "* `most_frequent`: always predicts the most frequent label in the training set.\n",
    "* `prior`: always predicts the class that maximizes the class prior (like “most_frequent”) and `predict_proba` returns the class prior.\n",
    "* `uniform`: generates predictions uniformly at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=7, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "for strategy in ['most_frequent', 'stratified', 'prior', 'uniform']:   # Iterate over different strategies\n",
    "    dummy = DummyClassifier(strategy=strategy, random_state=2)\n",
    "    dummy.fit(X_train, y_train)\n",
    "    score = dummy.score(X_test, y_test)\n",
    "    print(\"{:<15}| score = {:.3f}\".format(strategy, score))  # formatted print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To our alarm, the algorithm we thought was showing some promise is *little better than random classification*; in fact it is **worse** than one variety of the random strategy.$^1$\n",
    "\n",
    "There are a couple problems here.  One is the dataset is much too small to be a good fit for machine learning algorithms.  Discovering subtle patterns usually requires fairly extensive data.  Another problem *may be* that there simply is not a strong enough pattern in the data to meaningfully extract conclusions.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "<small><i>$^1$A confession is in order: I tried a few different `random_state` values to find one that produced this imbalance.  But *only a few* and the fact any random seed might produce better results is not a good sign.</i></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more encouraging dataset\n",
    "\n",
    "For demonstration purposes, I have also constructed a *fake* dataset by replicating the information in the simple data 50 times, but then randomly biasing features to be more predictive.  This is terrible practice for anything real, of course.  This gives us 5800 rows and data with the same features, but more predictive power, just as a pedagogical dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fake_learning = pd.read_csv('data/FakeLearning.csv')  # take on new data (which are replicated)\n",
    "X_fake = fake_learning.drop(\"Success\", axis=1)\n",
    "y_fake = fake_learning.Success\n",
    "print(\"Size of X=\", X_fake.shape)\n",
    "print(\"Size of y=\", y_fake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fake, y_fake, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=7, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "for strategy in ['most_frequent', 'stratified', 'prior', 'uniform']:\n",
    "    dummy = DummyClassifier(strategy=strategy, random_state=2)\n",
    "    dummy.fit(X_train, y_train)\n",
    "    score = dummy.score(X_test, y_test)\n",
    "    print(\"{:<15}| score = {:.3f}\".format(strategy, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we notice with this change to the size and (artificial) predictiveness of the data is that `DummyClassifier` stays pretty much the same, and `DecisionTreeClassifier` gets a lot better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick comparison of many classifiers in scikit-learn\n",
    "\n",
    "> **\"The first 90 percent of the code accounts for the first 90 percent of the development time. The remaining 10 percent of the code accounts for the other 90 percent of the development time.\"** –Tom Cargill, Bell Labs\n",
    "\n",
    "Having done the 90% of our work that was needed for data cleanup, the next 90% can be spent on model selection. Better hyperparameters than those chosen below (mostly defaults) are likely to identify better fits. Moreover, the few classifiers listed are by no means all of those in scikit-learn.\n",
    "\n",
    "This code is mostly based on the Scikit-learn [Classifier Comparison](http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html).\n",
    "\n",
    "> Code source: Gaël Varoquaux & Andreas Müller<br/>\n",
    "> Modified for documentation by Jaques Grobler<br/>\n",
    "> License: BSD 3 clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the large (but fake) dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fake, y_fake, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustrate how to use different classifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# define a dictionary for different classifiers and their parameters\n",
    "classifiers = {\n",
    "    \"Dummy\"        : DummyClassifier(strategy='uniform', random_state=2),\n",
    "    \"KNN(3)\"       : KNeighborsClassifier(3), \n",
    "    \"RBF SVM\"      : SVC(gamma=2, C=1), \n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=7), \n",
    "    \"Random Forest\": RandomForestClassifier(max_depth=7, n_estimators=10, max_features=4), \n",
    "    \"Neural Net\"   : MLPClassifier(alpha=1), \n",
    "    \"AdaBoost\"     : AdaBoostClassifier(),\n",
    "    \"Naive Bayes\"  : GaussianNB(), \n",
    "    \"QDA\"          : QuadraticDiscriminantAnalysis(),\n",
    "    \"Linear SVC\"   : LinearSVC(),\n",
    "    \"Linear SVM\"   : SVC(kernel=\"linear\"), \n",
    "    \"Gaussian Proc\": GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have moved to a larger dataset (of 5k items) some models can take **considerable time** to train.  This can often become a significant practical consideration in choices.  Fortunately, prediction time is almost always vastly quicker than training time.  It is often worthwhile to sink hours, or days, into training times if it will produce better models; those models can usually be used for predictions in orders of magnitude less time (usually with better big-O efficiency than training).\n",
    "\n",
    "Let us first compare the first few classifiers in the dictionary we define above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "nfast = 10      # Run the first nfast learner. Don't run the very slow ones at the end\n",
    "head = list(classifiers.items())[:nfast]\n",
    "\n",
    "for name, classifier in head:\n",
    "    start = time()                     # remember starting training time\n",
    "    classifier.fit(X_train, y_train)\n",
    "    train_time = time() - start        # get the total training time\n",
    "    start = time()\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    score_time = time()-start         # get the score time\n",
    "    print(\"{:<15}| score = {:.3f} | time = {:,.3f}s/{:,.3f}s\".format(name, score, train_time, score_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many classifiers scale training time linearly with sample size.  So for those fortunate ones, training on a million observations will simply take 100x as long as training on ten thousand observations.  However, a few classifiers have worse big-O complexities than this.  SVC with a linear kernel is $O(N^2)$ and Gaussian Process is $O(N^3)$, making them generally infeasible for large training sets.  Interestingly, `LinearSVC` implements an SVC linear kernel differently, making it $O(N)$ complexity, but also resulting in dramatically worse results in many tests I have tried.\n",
    "\n",
    "```\n",
    "Dummy          | score = 0.508 | time = 0.00s/0.00s\n",
    "KNN(3)         | score = 0.588 | time = 0.01s/0.03s\n",
    "RBF SVM        | score = 0.621 | time = 0.42s/0.19s\n",
    "Decision Tree  | score = 0.821 | time = 0.02s/0.00s\n",
    "Random Forest  | score = 0.844 | time = 0.02s/0.00s\n",
    "Neural Net     | score = 0.807 | time = 0.20s/0.03s\n",
    "AdaBoost       | score = 0.840 | time = 0.12s/0.02s\n",
    "Naive Bayes    | score = 0.806 | time = 0.00s/0.00s\n",
    "QDA            | score = 0.569 | time = 0.06s/0.00s\n",
    "Linear SVC     | score = 0.773 | time = 0.141s/0.001s\n",
    "Linear SVM     | score = 0.819 | time = 166.78s/0.05s\n",
    "Gaussian Proc  | score = 0.621 | time = 3,334.28s/0.31s\n",
    "```\n",
    "\n",
    "Within the range of classifiers, all have advantages against some datasets.  Other than `DummyClassifier` none of the classifiers lack advantages for at least some range of datasets.  The scores we found against the artificially expanded and weighted data suggests one we might look at more closely for the actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importances revisited and AdaBoost Classifier\n",
    "\n",
    "One of the classifiers that did well in our playing around is `AdaBoostClassifier`.  Unfotunately, when we return to the initial smaller and unskewed dataset, it has the same generally rather low score as `DesicionTreeClassifier`.  It may simply be that the underlying data has little predictive value in this case.  If the target is really independent/orthogonal to all the other features, there is nothing a machine learning model can predict. \n",
    "\n",
    "But one thing nice about `AdaBoostClassifier` is that it provides **feature importances** like `DecisionTreeeClassifier` and `RandomForestClassifier`.  This produces about the same predictive value, while focusing on very different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier  # select AdaBoost\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.read_csv('data/HumansLearning_X.csv', index_col=0)\n",
    "y = pd.read_csv('data/HumansLearning_y.csv', squeeze=True, header=None)\n",
    "print(\"Size of X=\", X.shape)\n",
    "print(\"Size of y=\", y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember the old not-that-great score via Decision Tree\n",
    "tree = DecisionTreeClassifier(max_depth=7, random_state=0) \n",
    "tree.fit(X_train, y_train)\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Adaboost score is simlarly not-that-great\n",
    "ab = AdaBoostClassifier()\n",
    "ab.fit(X_train, y_train)\n",
    "ab.score(X_test, y_test)   # show accuracy of AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit on the **entire data set** again, as before.  And look at the feature importances in contrast between the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=7, random_state=0).fit(X, y)\n",
    "pd.Series(tree.feature_importances_, index=X.columns).sort_values(ascending=False).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = AdaBoostClassifier().fit(X, y)\n",
    "pd.Series(ab.feature_importances_, index=X.columns).sort_values(ascending=False).head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting result here is that AdaBoost produces **much more intuitive weights** than does a decision tree.  Decision tree puts relatively equal weights on many features, most of which we would not guess are important.  AdaBoost puts high weights on just a couple features, and very little on any others., and those are the ones that a human would guess are likely to be important.  This result may not apply across all datasets, but it probably will in many.\n",
    "\n",
    "The documentation describes AdaBoost like this:\n",
    "\n",
    "> An AdaBoost classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases. This class implements the algorithm known as AdaBoost-SAMME. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass classification\n",
    "\n",
    "For simplification, we looked at a binary classification problem so far, how about multiclass?  \n",
    "\n",
    "Let us use a more real-world example that is included with scikit-learn, a dataset of **handwritten digits**, similar to the MNIST dataset often used to test neural network accuracy.\n",
    "\n",
    "> This dataset is made up of 1797 8x8 images. Each image, like the one shown below, is of a hand-written digit. In order to utilize an 8x8 figure like this, we’d have to first *transform each impage into a feature vector with length 64.*\n",
    "\n",
    "Reading the description, even though we normally think of an image as a $width \\times height$ array, the representation here is simply of independent features for each pixel of the image.\n",
    "\n",
    "To model this we will use `LogisticRegression`.  Despite its name, this model is a classifier not a regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix  # we need this because it is more than 2 classes\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us understand the nature of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Features:\",\n",
    "      digits.data.shape, \n",
    "      digits.data.dtype, \n",
    "      \"\\n  Target:\",\n",
    "      digits.target.shape, \n",
    "      digits.target.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 10, figsize=(16, 2))\n",
    "for n in range(10):\n",
    "    ax[n].imshow(digits.images[n], cmap=plt.cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A multiclass confusion matrix\n",
    "\n",
    "In a binary classification problems, the confusion matrix has a shape of (2, 2). In a multi-class problem, the confusion matrix has a shape (n_classes, n_classes) to show the correct vs incorrect classification counts for each class versus every other class.\n",
    "\n",
    "A perfect confusion matrix has **positive main diagonal** and **zeros elsewhere**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, random_state=0)\n",
    "\n",
    "# Perform a logistic regression\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions against the test set\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "# Find the accuracy of the predictions against the true classes\n",
    "print(\"accuracy: %0.3f\" % accuracy_score(y_test, pred))\n",
    "\n",
    "# Show the confusion matrix\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the [`mglearn` helper package for *Introduction to Machine Learning with Python*](https://github.com/amueller/mglearn) to present these results in a beautified way.  This nice, Free Software package from sckit-learn core developer Andreas Mueller has a number of convenient utilities, and is included in the archive of this zipfile.  You might want to check the original repository to see if he has updated it since it was bundled here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import src.mglearn as mglearn  # load mglearn module under the sub-directory src\n",
    "\n",
    "plt.figure()\n",
    "scores_image = mglearn.tools.heatmap(confusion_matrix(y_test, pred), \n",
    "                                     xlabel='Predicted label', \n",
    "                                     ylabel='True label',\n",
    "                                     xticklabels=digits.target_names, \n",
    "                                     yticklabels=digits.target_names,\n",
    "                                     cmap=plt.cm.gray_r, \n",
    "                                     fmt=\"%d\")    \n",
    "\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's output precision, recall, f1-score and suppot for all classes\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction probabilities\n",
    "\n",
    "Most classification models produce not only a specific class prediction, but also a probability of each class membership.  The actual prediction is simply the most probable class according to the model.  For example, looking at one of the digit images, we can see the likelihood—according to the model—that it represents each possible value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "n = randint(0,len(digits.images))    # display it\n",
    "plt.imshow(digits.images[n], cmap=plt.cm.gray_r)\n",
    "probs = pd.Series(lr.predict_proba(digits.data[n:n+1]).flatten()) \n",
    "\n",
    "# print out the digit and its probability in descending order\n",
    "for digit, prob in probs.sort_values(ascending=False).iteritems():\n",
    "    print(digit, \"| %.4f%%\" % (100*prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier boundary comparison\n",
    "\n",
    "On of the main tradeoffs among classifiers (and also among regressors) is between complexity and generalization.  For example, `LinearRegression` and `LogisticRegression` are very simple models that cannot fit complicated relationships. On the other hand, it is hard to overfit a LinearRegression.\n",
    "\n",
    "In contrast, `KNeighborsClassifier` is not very general.  At the extreme, with one neighbor, the model essentially just memorizes the data.  On the other hand, for overly large `n_neighbors`, the model will tend to only predict the most commonly occurring label.  That said, there are many datasets for which K nearest neighbor is an excellent choice.\n",
    "\n",
    "The below code is taken directly from the [scikit-learn documentation](http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html).  It is a nice way to explore and visually summarize the different decision boundaries that various classifiers product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and lessons learnt \n",
    "\n",
    "In this notebook, we learn about\n",
    "- Decision tree and how it outputs feature importances\n",
    "- Display of result using decision tree\n",
    "- Use of DummyClassifier and how we loop through different classifier strategy\n",
    "- A glimpse of other classifers like: neural network, KNN, SVC, SVM, Linear SVC, Adaboost..etc\n",
    "- Concept of training time and score of each classifier\n",
    "- Feature importance of Adaboost\n",
    "- Multiclass classification\n",
    "- Example of digit recognition\n",
    "- Confusion matrix and the use of  mglearn to display confusion matrix\n",
    "- Use of classification_report to display precision, recall, f1-score and suppot for all classes\n",
    "- Prediction probabilities for each testing input\n",
    "\n",
    "In the next lession, we will go over **Regression**. We explored the classifer APIs and looked at a few examples of different datasets and different classifiers.  We had a passing exposure to hyperparameters and validation.  In the next lesson we examine regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
